{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70aef590",
   "metadata": {},
   "source": [
    "# Processing MITGCM data for Mixed-layer depth Analysis \n",
    "\n",
    "**Purpose**: Code for computing the mixed layer depth. \n",
    "\n",
    "**Luke Colosi | lcolosi@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f817d5",
   "metadata": {},
   "source": [
    "Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "from xmitgcm import open_mdsdataset\n",
    "import numpy as np\n",
    "import gsw\n",
    "\n",
    "#--- Other Functions ---# \n",
    "sys.path.append(\"/home/lcolosi/AirSeaCoupling/tools/\")\n",
    "import cartopy_figs as cart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b7656",
   "metadata": {},
   "source": [
    "Set data analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters \n",
    "delta_t = 150  # Time steps of the raw model run (by raw, I mean the time increments that the model is ran at, not time increments that the diagnostics are output at). Units: seconds\n",
    "\n",
    "# Set time and space parameters  \n",
    "lat_bnds  = [32.5, 35]                                           # Specifies the latitude bounds for the region to analyze\n",
    "lon_bnds  = [236.0, 241.0]                                       # Specifies the longitude bounds for the region to analyze\n",
    "encoding  = {'time': {'units': 'seconds since 2015-12-01 2:00'}} # Specifies the start time of the model run\n",
    "\n",
    " \n",
    "# Set path to project directory\n",
    "PATH_GRID   = '/data/SO2/SWOT/GRID/BIN/'                    # Space and time grid of the model \n",
    "PATH_OUTPUT = '/data/SO2/SWOT/MARA/RUN4_LY/DIAGS_HRLY/'     # Diagnostics of the model\n",
    "PATH_nc     = '/data/SO3/lcolosi/mitgcm/SWOT_MARA_RUN4_LY/'  # Directory to save netCDFs \n",
    "PATH_figs   = '/home/lcolosi/AirSeaCoupling/figs_server/mitgcm/preliminary/'\n",
    "file_dim    = '3D'                                          # Set the dimension of the data (to include the depth or not)\n",
    "\n",
    "# Set plotting parameters \n",
    "fontsize = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88096371",
   "metadata": {},
   "source": [
    "Load the grid and diagnostics data into a python structure. The diagnostics that we will be looking at include: \n",
    "\n",
    "1. **Potential Temperature** $\\theta$: $^\\circ C$\n",
    "2. **Salinity** $S$: $g/kg$\n",
    "3. **Stratification** $\\frac{d\\sigma}{dz}$: $kg/m^4$\n",
    "4. **Zonal, meridional, and vertical velocity components**  $\\textbf{u} = (u,v,w)$: $m/s$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc02772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset \n",
    "ds = open_mdsdataset(\n",
    "    PATH_OUTPUT,                    # File path where the model output data is stored (.data and .meta files)\n",
    "    PATH_GRID,                      # File path to the grid data of the model \n",
    "    iters='all',                    # Specifies which iteration of the data to load\n",
    "    delta_t=delta_t, \n",
    "    ignore_unknown_vars=False,      # Specifies whether to ignore any unknown variables that may appear in the dataset\n",
    "    prefix=['diags_' + file_dim],   # List of prefixes to filter the variables in the dataset\n",
    "    ref_date=\"2015-01-01 02:00:00\", # Specifies the starting point of the simulation time (which may include the spin up time before diagnostics are output)\n",
    "    geometry='sphericalpolar',      # Specifies the  grid's geometry is spherical-polar. \n",
    "    #chunks={'i': 48, 'i_g': 48, 'j': 56,  'j_g': 56, 'k': 10, 'k_u':10, 'k_l':10, 'k_p1':10} # Chunck data upload into 48x56 pieces (spatial grid is divided into 12 chunks along the x and y axes) chunks={'i': 48, 'i_g': 48, 'j': 56,  'j_g': 56, 'k': 10, 'k_u':10, 'k_l':10, 'k_p1':10, 'time':1} chunks={'XC':48, 'YC':56, 'XG':48, 'YG':56, 'Z':10, 'Zp1':10, 'Zu':10, 'Zl':10, 'time':1}\n",
    ")\n",
    "\n",
    "# Convert all variables and coordinates in the dataset to little-endian (the format how multi-byte values are stored into memory)\n",
    "\n",
    "#--- Variables ---#\n",
    "for var in ds.data_vars:\n",
    "    if ds[var].dtype.byteorder == '>' or (ds[var].dtype.byteorder == '=' and sys.byteorder == \"big\"):  # Check if big-endian\n",
    "        ds[var] = ds[var].astype(ds[var].dtype.newbyteorder('<'))\n",
    "\n",
    "#--- Coordinates ---# \n",
    "for coord in ds.coords:\n",
    "    if ds[coord].dtype.byteorder == '>'or (ds[coord].dtype.byteorder == '=' and sys.byteorder == \"big\"):  # Check if big-endian\n",
    "        ds[coord] = ds[coord].astype(ds[coord].dtype.newbyteorder('<'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88caad",
   "metadata": {},
   "source": [
    "Slice the array based on latitude and longitude bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e917963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice array\n",
    "ds_subset = ds.sel(\n",
    "    XG=slice(*lon_bnds),\n",
    "    YG=slice(*lat_bnds),\n",
    "    XC=slice(*lon_bnds),\n",
    "    YC=slice(*lat_bnds),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6332a",
   "metadata": {},
   "source": [
    "Compute mixed layer depth for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gsw\n",
    "\n",
    "def compute_mld_profiles(SA, pt, depth, lat, threshold=0.03, ref_depth=10):\n",
    "    \"\"\"\n",
    "    Compute Mixed Layer Depth (MLD) for multiple profiles using potential density threshold method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    SA : ndarray\n",
    "        Absolute Salinity [g/kg], shape (n_depths, n_profiles).\n",
    "    pt : ndarray\n",
    "        Potential Temperature [Â°C], shape (n_depths, n_profiles).\n",
    "    depth : ndarray\n",
    "        Depth levels [m, positive down], shape (n_depths,).\n",
    "    lat : float or ndarray\n",
    "        Latitude(s) [degrees north], scalar or shape (n_profiles,).\n",
    "    threshold : float, optional\n",
    "        Potential density difference threshold [kg/m^3]. Default is 0.03.\n",
    "    ref_depth : float, optional\n",
    "        Reference depth [m] near the surface for baseline density. Default is 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mld : ndarray\n",
    "        Mixed Layer Depths [m] for each profile, shape (n_profiles,).\n",
    "        np.nan if MLD not found.\n",
    "    \"\"\"\n",
    "\n",
    "    SA = np.asarray(SA)\n",
    "    pt = np.asarray(pt)\n",
    "    depth = np.asarray(depth)\n",
    "\n",
    "    if SA.shape != pt.shape:\n",
    "        raise ValueError(\"SA and pt must have the same shape (n_depths, n_profiles)\")\n",
    "\n",
    "    n_depths, n_profiles = SA.shape\n",
    "    mld = np.full(n_profiles, np.nan)\n",
    "\n",
    "    # Broadcast latitude if it's a scalar\n",
    "    if np.isscalar(lat):\n",
    "        lat = np.full(n_profiles, lat)\n",
    "    lat = np.asarray(lat)\n",
    "\n",
    "    for i in range(n_profiles):\n",
    "        # Pressure from depth\n",
    "        p = gsw.p_from_z(-depth, lat[i])\n",
    "\n",
    "        # Potential density anomaly referenced to 0 dbar\n",
    "        sigma0 = gsw.sigma0(SA[:, i], pt[:, i])  # shape: (n_depths,)\n",
    "\n",
    "        # Reference density at ref_depth\n",
    "        idx_ref = np.argmin(np.abs(depth - ref_depth))\n",
    "        rho_ref = np.mean(sigma0[max(0, idx_ref - 1):idx_ref + 2])\n",
    "\n",
    "        # Find first depth where density exceeds reference by threshold\n",
    "        exceed = np.where(sigma0 > rho_ref + threshold)[0]\n",
    "        if exceed.size > 0:\n",
    "            mld[i] = depth[exceed[0]]\n",
    "\n",
    "    return mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = np.array([\n",
    "    [34.5, 34.4, 34.3],\n",
    "    [34.6, 34.5, 34.4],\n",
    "    [34.7, 34.6, 34.5],\n",
    "    [34.8, 34.8, 34.6],\n",
    "    [34.9, 34.9, 34.7]\n",
    "])\n",
    "\n",
    "pt = np.array([\n",
    "    [18.0, 18.1, 18.2],\n",
    "    [17.9, 18.0, 18.1],\n",
    "    [17.5, 17.8, 18.0],\n",
    "    [16.0, 17.5, 17.8],\n",
    "    [14.0, 16.0, 17.0]\n",
    "])\n",
    "\n",
    "depth = np.array([0, 5, 10, 20, 30])  # m\n",
    "lat = 30.0\n",
    "\n",
    "mld = compute_mld_profiles(SA, pt, depth, lat)\n",
    "print(\"Mixed Layer Depths (m):\", mld)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pt,-depth,'.-')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(SA, -depth,'.-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airsea_coupling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
